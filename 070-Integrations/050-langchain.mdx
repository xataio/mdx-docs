---
title: LangChain with Xata
navTitle: LangChain
keywords: ['AI', 'vector store', 'memory store']
description: Use Xata as a vector store or memory store within LangChain
slug: integrations/langchain
published: true
---

<<Alert status="warning">
This integration is deprecated and no longer recommended for use in new applications. It will continue to be maintained, but no further enhancements are planned.

</Alert>

[LangChain](https://www.langchain.com/) is an open-source framework designed to simplify the development of applications driven by language models, especially large language models (LLMs).
Rather than just using APIs, LangChain encourages applications to link with data sources and interact dynamically with the environment. This framework brings two main advantages:

- presents readily deployable building blocks tailored for using language models
- introduces the concept of "chains" that combines these building blocks for specific tasks, making it easy to start and customize high-level tasks.

Langchain can be used to create chatbots, find answers using sources, study structured data, and more.

## Integration options

With this LangChain integration, Xata can serve as a versatile solution by either operating as a vector store optimized for high-dimensional data storage and similarity searches, or as a memory store for management of frequently accessed data.

- Xata as a [vector store in LangChain](https://python.langchain.com/docs/integrations/vectorstores/xata) (Python): Use Xata as a vector store within LangChain. This integration enables you to store documents with embeddings in a Xata table, facilitating vector searches. Leveraging the [Python SDK](/docs/sdk/python/overview) this integration supports metadata-based filtering, in which metadata is represented through Xata columns.

- Xata as a [vector store in LangChain.js](https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/xata) (TypeScript/JavaScript): Similar to the Python integration, you can incorporate Xata as a vector store within LangChain.js. Xata includes a built-in vector type that can be added to tables for similarity search. With the LangChain integration, vectors are added to Xata and used to find similar items.

- Xata as a [memory store in LangChain](https://python.langchain.com/docs/integrations/memory/xata_chat_message_history): Use Xata as a memory store within LangChain for storing chat message history. This is particularly useful for AI chat sessions, functioning as a "memory" for applications powered by large language models (LLM). The messages are effectively stored to enhance contextual understanding.

- Xata as a [memory store in LangChain.js](https://js.langchain.com/docs/modules/memory/integrations/xata) (TypeScript/JavaScript): Use Xata databases for longer-term persistence of chat sessions with the `XataChatMessageHistory` class. This option offers the same functionality as the Python integration, adapted for TypeScript/JavaScript environments.
